{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d20aae-d441-44f8-8c06-5e8ffa8e7a67",
   "metadata": {},
   "source": [
    "# Formulas for EA data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab5190-190b-4079-974e-4ee6815282cd",
   "metadata": {},
   "source": [
    "These functions can be used to extract data from EA's API. This was only a notebook to test the usage of EA's functions.\n",
    "\n",
    "Source: https://developer.energyaspects.com/recipes/ea-data-api-get-data-into-a-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77139142-ebfd-490c-a4b3-541a810a8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# this is the timeseries endpoint, which retrieves your\n",
    "api_timeseries_endpoint = \"https://api.energyaspects.com/data/timeseries/\"\n",
    "\n",
    "api_metadata_endpoint = \"https://api.energyaspects.com/data/datasets/timeseries/\"\n",
    "\n",
    "\n",
    "def get_metadata(dataset_ids: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieves the metadata in a Dataframe for all the provided dataset ids.\n",
    "\n",
    "    Args:\n",
    "        dataset_ids: The dataset ids you want to retrieve metadata for\n",
    "\n",
    "    Returns:\n",
    "        The metadata in a pandas Data Frame\n",
    "    \"\"\"\n",
    "    metadata_df = pd.DataFrame()\n",
    "    for _id in dataset_ids:\n",
    "        response = pd.read_json(api_metadata_endpoint + str(_id) + f'?api_key={api_key}')\n",
    "        metadata_df[_id] = response.metadata\n",
    "    metadata_df.loc[\"release_date\", :] = metadata_df.apply(lambda col: col[\"release_dates\"][-1])\n",
    "    return metadata_df\n",
    "\n",
    "\n",
    "def get_data_in_long_format(dataset_ids: list, file_format: str = \"xlsx\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gets the data from the API for a given list of dataset ids and then combines with metadata in a long format.\n",
    "\n",
    "    Args:\n",
    "        dataset_ids: A list of the dataset ids you want to extract\n",
    "        file_format: The API endpoint you want to use\n",
    "\n",
    "    Returns:\n",
    "        The combined dataset timeseries with the metadata in a long format\n",
    "    \"\"\"\n",
    "    ids_str = \",\".join([str(i) for i in dataset_ids])\n",
    "    query = api_timeseries_endpoint + file_format + f\"?api_key={api_key}&dataset_id={ids_str}\"\n",
    "    metadata = get_metadata(dataset_ids)\n",
    "    if file_format == \"xlsx\":\n",
    "        xlsx_header = \"dataset_id\"\n",
    "        # this will set the header as the dataset_ids\n",
    "        query = query + f\"&xlsx_header={xlsx_header}\"\n",
    "        # reads the data and sets the dates to datetime object\n",
    "        df = pd.read_excel(query, parse_dates=[\"Date\"], sheet_name=\"Data\")\n",
    "        # melt the dataframe so that the dataset_ids are columns\n",
    "        data_long = df.melt(id_vars=\"Date\", value_name=\"value\", var_name=\"dataset_id\")\n",
    "        # get the metadata with the dataset_id as a column\n",
    "        metadata_transposed = metadata.T.reset_index().rename(columns={\"index\": \"dataset_id\"})\n",
    "        # combine in a long format\n",
    "        df = pd.merge(data_long, metadata_transposed, on=\"dataset_id\", how=\"left\")\n",
    "    elif file_format == \"csv\":\n",
    "        # this will be returned as a dataframe with the Descriptions as the columns. So you will need to merge on\n",
    "        # description if you use CSV as an option for getting the data\n",
    "        df = pd.read_csv(query, parse_dates=[\"Date\"])\n",
    "        # switching to long format\n",
    "        data_long = df.melt(id_vars=\"Date\", value_name=\"value\", var_name=\"description\")\n",
    "        # transposing the metadata to merge on long dataframe\n",
    "        metadata_transposed = metadata.T.reset_index().rename(columns={\"index\": \"dataset_id\"})\n",
    "        # combining metadata and data in long format\n",
    "        df = pd.merge(data_long, metadata_transposed, on=\"description\", how=\"left\")\n",
    "    elif file_format == \"json\":\n",
    "        # this will return it in a long format with the dates as columns and the metadata next to it.\n",
    "        df = pd.read_json(query)\n",
    "        # Reverts the json nested dictionaries for the metadata and data into columns\n",
    "        df = pd.concat([df[\"dataset_id\"], df.data.apply(pd.Series), df.metadata.apply(pd.Series)], axis=1)\n",
    "        # Finds all the non timestamp columns.\n",
    "        id_vars = [i for i in df.columns if not i[0].isdigit()]\n",
    "        # Melts the dataframe in a long format.\n",
    "        df = df.melt(id_vars=id_vars, value_name=\"value\", var_name=\"Date\")\n",
    "    else:\n",
    "        raise TypeError(\"Please provide a valid file format\")\n",
    "    # ensure that the forecast_start_date column is also a datetime.\n",
    "    if \"forecast_start_date\" in df.columns:\n",
    "        df.loc[:, \"forecast_start_date\"] = pd.to_datetime(df[\"forecast_start_date\"])\n",
    "\n",
    "    return df.sort_values(by=[\"dataset_id\", \"Date\"])\n",
    "\n",
    "\n",
    "def get_data(dataset_ids: list, api_key: str, file_format: str = \"csv\", dataset_id_as_header: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gets the data from the API for a given list of dataset ids and then combines with metadata in a long format.\n",
    "    Args:\n",
    "        dataset_ids: A list of the dataset ids you want to extract\n",
    "        file_format: The API endpoint you want to use\n",
    "        dataset_id_as_header: If True make the dataset_id as the header. Only used in the csv/xlsx endpoints\n",
    "    Returns:\n",
    "        The combined dataset timeseries with the metadata in a wide format\n",
    "    \"\"\"\n",
    "    ids_str = \",\".join([str(i) for i in dataset_ids])\n",
    "    # constructs the API url request link\n",
    "    query = api_timeseries_endpoint + file_format + f\"?api_key={api_key}&dataset_id={ids_str}\"\n",
    "    if file_format == \"csv\":\n",
    "        if dataset_id_as_header:\n",
    "            query += \"&column_header=dataset_id\"\n",
    "        # reads the data and sets the dates to datetime object\n",
    "        df = pd.read_csv(query, parse_dates=[\"Date\"])\n",
    "    elif file_format == \"xlsx\":\n",
    "        if dataset_id_as_header:\n",
    "            query += \"&column_header=dataset_id\"\n",
    "        # reads the data and sets the dates to datetime object\n",
    "        df = pd.read_excel(query, parse_dates=[\"Date\"], sheet_name=\"Data\")\n",
    "    elif file_format == \"json\":\n",
    "        # this will return it in a long format with the dates as columns and the metadata next to it.\n",
    "        df = pd.read_json(query)\n",
    "    else:\n",
    "        raise TypeError(\"Please provide a valid file format\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cac548-3905-4cbd-8431-75109a70f48e",
   "metadata": {},
   "source": [
    "The command lines below are just for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b412b82-9356-4bf5-b7d2-bef46f8aac9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif __name__ == \\'__main__\\':\\n\\n    # either type your api key here, or use Environment variables to pass.\\n    api_key = \"aed5e4a5-141c-4f34-84cb-b3d991fc0ba5\"\\n    \\n    # set the dataset ids you want to extract here\\n    ids = [7123]\\n\\n    # this will get all the data in a long format\\n    # df = get_data_in_long_format(ids)\\n    \\n    # this will get all the data in a wide format with dataset id\\'s as column names\\n    # df = get_data(ids, dataset_id_as_header=True)\\n    \\n    # this will get all the data in a wide format with descriptions as column names\\n    df = get_data(ids, api_key)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # either type your api key here, or use Environment variables to pass.\n",
    "    api_key = \"aed5e4a5-141c-4f34-84cb-b3d991fc0ba5\"\n",
    "    \n",
    "    # set the dataset ids you want to extract here\n",
    "    ids = [7123]\n",
    "\n",
    "    # this will get all the data in a long format\n",
    "    # df = get_data_in_long_format(ids)\n",
    "    \n",
    "    # this will get all the data in a wide format with dataset id's as column names\n",
    "    # df = get_data(ids, dataset_id_as_header=True)\n",
    "    \n",
    "    # this will get all the data in a wide format with descriptions as column names\n",
    "    df = get_data(ids, api_key)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0033466f-026a-4db1-948b-09835bded8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
